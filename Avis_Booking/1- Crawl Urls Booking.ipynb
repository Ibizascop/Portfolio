{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6924c56a",
   "metadata": {},
   "source": [
    "Intro) A une époque ou la mahorité des réservations d\"hôtels se font via des sites tiers tels que Booking.com, l'e-reputation est devenu un élément de préoccupation majeur pour les hôtels.Être capable d'analyser et d'extraire des insights à partir des commentaires en ligne (Note client moyenne, comparaison par rapport aux concurrents, mentions positivies/negatives...) est donc un atout pour les opérateurs d'hôtels.\n",
    "\n",
    "Le but de ce projet est donc de réaliser une brève analyse NLP de 100k commentaires booking laissé sur les établissements du département des Pyrénnées-Atlantiques (64) entre 2019 et 2022.\n",
    "\n",
    "Dans ce notebook, on lance un crawl via selenium pour recuperer les urls booking des établissements des Pyréennées Atlantiques. Ces urls seront ensuite utilisées par le fichier 2- Crawl Avis Booking pour récupérér les avis de chaque établissement.\n",
    "\n",
    "Etant donné que Booking.com n'affiche que 1000 établissements en même maximum, et que sur le départment 64 il \n",
    "y en a 2500+ (https://www.booking.com/region/fr/pyrenees-atlantiques.fr.html), on va filtrer au fur et à mesure\n",
    "les résultats en utilisant les filtres : étoiles, types d'établissements et quartiers pour diminuer le nombre de résultats.\n",
    "Cela permettra d'obtenir l'ensemble des +2500 établissements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import concurrent.futures\n",
    "\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import Future\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "#Ignore deprectation & SSL certificate errors\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings('ignore', message='Unverified HTTPS request')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4071f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define subfunction to get all accomodation urls on a page\n",
    "def urlfetch():\n",
    "    \"\"\"\n",
    "    Fonction permettant de récupérer les urls des établissements\n",
    "    affichés sur une page de résultats booking.\n",
    "    Arguments:\n",
    "        Pas d'arguments\n",
    "        \n",
    "    Renvoit: Null\n",
    "        Ecrit sur le fichier de résultat les urls des établissements\n",
    "    \"\"\"\n",
    "    lecture_urls = chrome.find_elements(By.CSS_SELECTOR,\"a[class='e13098a59f']\")\n",
    "    hotels_urls= [url.get_attribute(\"href\").split(\"?\")[0] for url in lecture_urls]\n",
    "    for urlhotel in hotels_urls:\n",
    "        with open(\"booking_url.txt\",'a',encoding =\"utf-8\") as file:\n",
    "            file.write(urlhotel)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main function\n",
    "def searchcityurl(booking_url):\n",
    "    \"\"\"\n",
    "    Fonction prenant en paramètre un url de ville, de région booking\n",
    "    et crawlant l'ensemble des établissements listés sur cette destination.\n",
    "    \n",
    "    Afin de contourner la limite de 1000 résultats affichés en même temps,\n",
    "    la function va, si nécessaire, cliquer sur les boutons de filtre booking pour \n",
    "    diminuer le nombre de résultats affichés afin de récupérer l'ensemble des \n",
    "    établissements segments par segments.\n",
    "    \n",
    "    Arguments:\n",
    "        booking_url : String : Un url de destination booking.\n",
    "        Par exemple : \"https://www.booking.com/region/fr/pyrenees-atlantiques.fr.html\"\n",
    "        \n",
    "    Renvoit: Null\n",
    "        Crawl et ecrit sur le fichier de résultat les urls des établissements\n",
    "        listés sur l'url de destination booking\n",
    "    \"\"\"\n",
    "    try :\n",
    "        for counter in range(5):\n",
    "            try:\n",
    "                #Driver\n",
    "                chrome_options = Options()\n",
    "                ua = UserAgent()\n",
    "                userAgent = ua.random\n",
    "                chrome_options.add_argument(f\"user-agent={userAgent}\")\n",
    "                path = r\"DRIVER_PATH\"\n",
    "                chrome = webdriver.Chrome(executable_path = path, options = chrome_options)\n",
    "                chrome.maximize_window()\n",
    "                \n",
    "                #Go to booking url\n",
    "                chrome.get(booking_url)\n",
    "                time.sleep(2)\n",
    "                break\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "                chrome.quit()\n",
    "                '''\n",
    "                PROCNAME = \"chromedriver\"\n",
    "                for proc in psutil.process_iter():\n",
    "                     if proc.name() == PROCNAME:\n",
    "                          proc.kill()'''\n",
    "        #Handle Popup\n",
    "        time.sleep(1)\n",
    "        pop_up=chrome.find_element(By.ID,'onetrust-reject-all-handler')\n",
    "        try:\n",
    "            pop_up.click()\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #Search hotels and accomodations\n",
    "        time.sleep(1)\n",
    "        search_button=chrome.find_element(By.CLASS_NAME,'sb-searchbox__button ')\n",
    "        chrome.execute_script(\"arguments[0].scrollIntoView();\", search_button)\n",
    "        search_button.click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #Second Popup\n",
    "        try:\n",
    "            pop_up=chrome.find_element(By.ID,'onetrust-accept-all-handler')\n",
    "            pop_up.click()\n",
    "            time.sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #Get Number of accomodations in city/region\n",
    "        element_=chrome.find_element(By.CSS_SELECTOR,\"h1[class='e1f827110f d3a14d00da']\")\n",
    "        if len(element_)>0:\n",
    "            element_=element.text\n",
    "            element_=element_.replace(' ','').strip()\n",
    "            try:\n",
    "                element_=element_.replace('\\xa0','').replace(' ','').strip()\n",
    "            except:\n",
    "                pass\n",
    "            element_c=re.findall(r\"(\\d+)\",element_)\n",
    "            element_c_seuil=int(element_c[0])\n",
    "        elif len(element_)==0:\n",
    "            element_ = chrome.find_element(By.CSS_SELECTOR,\"div[class='d8f77e681c']\")\n",
    "            element_=element.text\n",
    "            element_=element_.replace(' ','').strip()\n",
    "            try:\n",
    "                element_=element_.replace('\\xa0','').replace(' ','').strip()\n",
    "            except:\n",
    "                pass\n",
    "            element_c=re.findall(r\"(\\d+)Etablissementstrouvés\",element_)\n",
    "            element_c_seuil=int(element_c[0])\n",
    "        with open(\"Nombre_Etablissements_trouves.txt\",\"a\") as flog:\n",
    "            print(element_c_seuil,\" etablissements sur l'url: \",x,file=flog)\n",
    "        \n",
    "        #Bouton pour naviguer entre les pages\n",
    "            xpath_page_suivante = '//*[@id=\"search_results_table\"]/div[2]/div/div/div/div[6]/div[2]/nav/div/div[3]/button'\n",
    "        #1er cas : le nombre d'établissement <1000\n",
    "        if element_c_seuil<=1000:\n",
    "            #1ère page\n",
    "            urlfetch()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            #Get all other pages\n",
    "            lecture_toutes_pages=chrome.find_element(By.CSS_SELECTOR,\"li[class='f32a99c8d1']\")\n",
    "            #Pages suivantes\n",
    "            if len(lecture_toutes_pages)>0:\n",
    "                max_pages=[]\n",
    "                for page in lecture_toutes_pages:\n",
    "                    try :\n",
    "                        max_pages.append(int(re.findall(r'(\\d+)',page.text)[0]))\n",
    "                    except:\n",
    "                        pass\n",
    "                    max_page=max(max_pages)\n",
    "                #Wait until button for next page is visible\n",
    "                if max_page>1:\n",
    "                    for counter_refresh in range(5):\n",
    "                        try:\n",
    "                            element = WebDriverWait(chrome, 4).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                        except:\n",
    "                            try:\n",
    "                                chrome.refresh()\n",
    "                                time.sleep(3)\n",
    "                                element = WebDriverWait(chrome, 4).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                            except:\n",
    "                                continue\n",
    "                    try:\n",
    "                        #Click on next page button\n",
    "                        click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                        chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                        chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                        time.sleep(2)\n",
    "                    except:\n",
    "                        #Or Refresh and Click on next page button\n",
    "                        chrome.refresh()\n",
    "                        time.sleep(3)\n",
    "                        click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                        chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                        chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                        time.sleep(2)\n",
    "                    #Loop on all the other pages\n",
    "                    while True:\n",
    "                        try:\n",
    "                            #Keep 1st url to know if we reached the end of all the pages\n",
    "                            url_0=str(chrome.current_url)\n",
    "                            urlfetch()\n",
    "                            time.sleep(1)\n",
    "                            timeout = time.time() + 45\n",
    "                            try:\n",
    "                                element = WebDriverWait(chrome, 4).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                            except:\n",
    "                                try:\n",
    "                                    chrome.refresh()\n",
    "                                    element = WebDriverWait(chrome, 4).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                except:\n",
    "                                    break\n",
    "                            try:\n",
    "                                time.sleep(3)\n",
    "                                click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                time.sleep(2)\n",
    "                            except:\n",
    "                                chrome.refresh()\n",
    "                                time.sleep(3)\n",
    "                                click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                time.sleep(2)\n",
    "                            url_1=str(chrome.current_url)\n",
    "                        except:\n",
    "                            urlfetch()\n",
    "                            if len(chrome.find_elements(By.XPATH,xpath_page_suivante))>0:\n",
    "                                raise Exception(\"Failed at pressing next-page button-Timeout\")\n",
    "                                break\n",
    "                            else:\n",
    "                                raise Exception(\"Failed at pressing next-page button-Button not present...Check for completion\")\n",
    "                                break\n",
    "\n",
    "                        if url_0==url_1:\n",
    "                            break\n",
    "        #If more than 1000 accomodation listed, we start by filtering based on stars rating\n",
    "        elif element_c_seuil>1000:\n",
    "            listetoiles = []\n",
    "            try :\n",
    "                e1=chrome.find_element(By.CSS_SELECTOR,\"div[data-filters-item='class:class=1']\")\n",
    "                se1 = e1.now()[0]\n",
    "                de1={'label':se1.find_element(By.CSS_SELECTOR,\"div[class='a1b3f50dcd b2fe1a41c3 a1f3ecff04 db7f07f643 d1764ea78b']\").text.strip(),'count':int(se1.find(\"span\",{\"class\":\"d8eab2cf7f a414c2b280\"}).text.strip()),'id':'//input[@name=\"class=1\"]'}\n",
    "                listetoiles.append(de1)\n",
    "            except:\n",
    "                pass\n",
    "            try :\n",
    "                e2=chrome.find_element(By.CSS_SELECTOR,\"div[data-filters-item='class:class=2']\")\n",
    "                se2 = e2.now()[0]\n",
    "                de1={'label':se2.find_element(By.CSS_SELECTOR,\"div[class='a1b3f50dcd b2fe1a41c3 a1f3ecff04 db7f07f643 d1764ea78b']\").text.strip(),'count':int(se1.find(\"span\",{\"class\":\"d8eab2cf7f a414c2b280\"}).text.strip()),'id':'//input[@name=\"class=1\"]'}\n",
    "                listetoiles.append(de2)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                e3=chrome.find_element(By.CSS_SELECTOR,\"div[data-filters-item='class:class=3']\")\n",
    "                se3 = e3.now()[0]\n",
    "                de3={'label':se3.find_element(By.CSS_SELECTOR,\"div[class='a1b3f50dcd b2fe1a41c3 a1f3ecff04 db7f07f643 d1764ea78b']\").text.strip(),'count':int(se1.find(\"span\",{\"class\":\"d8eab2cf7f a414c2b280\"}).text.strip()),'id':'//input[@name=\"class=1\"]'}\n",
    "                listetoiles.append(de3)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                e4=chrome.find_element(By.CSS_SELECTOR,\"div[data-filters-item='class:class=4']\")\n",
    "                se4 = e4.now()[0]\n",
    "                de4={'label':se4.find_element(By.CSS_SELECTOR,\"div[class='a1b3f50dcd b2fe1a41c3 a1f3ecff04 db7f07f643 d1764ea78b']\").text.strip(),'count':int(se1.find(\"span\",{\"class\":\"d8eab2cf7f a414c2b280\"}).text.strip()),'id':'//input[@name=\"class=1\"]'}\n",
    "                listetoiles.append(de4)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                e5=chrome.find_element(By.CSS_SELECTOR,\"div[data-filters-item='class:class=5']\")\n",
    "                se5 = e5.now()[0]\n",
    "                de5={'label':se5.find_element(By.CSS_SELECTOR,\"div[class='a1b3f50dcd b2fe1a41c3 a1f3ecff04 db7f07f643 d1764ea78b']\").text.strip(),'count':int(se1.find(\"span\",{\"class\":\"d8eab2cf7f a414c2b280\"}).text.strip()),'id':'//input[@name=\"class=1\"]'}\n",
    "                listetoiles.append(de5)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                e0=chrome.find_element(By.CSS_SELECTOR,\"div[data-filters-item='class:class=0']\")\n",
    "                se0 = e5.now()[0]\n",
    "                de0={'label':se0.find_element(By.CSS_SELECTOR,\"div[class='a1b3f50dcd b2fe1a41c3 a1f3ecff04 db7f07f643 d1764ea78b']\").text.strip(),'count':int(se1.find(\"span\",{\"class\":\"d8eab2cf7f a414c2b280\"}).text.strip()),'id':'//input[@name=\"class=1\"]'}\n",
    "                listetoiles.append(de0)\n",
    "            except:\n",
    "                pass\n",
    "            #Save current url so we can reset filters \n",
    "            base1=chrome.current_url\n",
    "            #For each filter, we are gonna click ion the button filter,  check if there are less than 1000\n",
    "            #elements. If it the case, we can get all data. If not, we use a second filter (type of accomodation\n",
    "            #and neighboor) and so on.\n",
    "            #After its done for one rating filter, we reset the url and move on to the next rating filter\n",
    "            for z in listetoiles:\n",
    "                chrome.get(base1)\n",
    "                try :\n",
    "                    time.sleep(2)\n",
    "                    elem = chrome.find_element(By.XPATH,z['id'])\n",
    "                    chrome.execute_script(\"arguments[0].scrollIntoView();\", elem)\n",
    "                    chrome.execute_script(\"arguments[0].click();\", elem)\n",
    "                    time.sleep(2)\n",
    "                    if z['count']<=1000:\n",
    "                        urlfetch()\n",
    "                        time.sleep(1)\n",
    "                        try:\n",
    "                            element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                        except:\n",
    "                            try:\n",
    "                                chrome.refresh()\n",
    "                                element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                            except:\n",
    "                                continue\n",
    "                        try:\n",
    "                            time.sleep(2)\n",
    "                            click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                            chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                            chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                            time.sleep(2)\n",
    "                        except:\n",
    "                            print(traceback.format_exc())\n",
    "                            chrome.refresh()\n",
    "                            time.sleep(2)\n",
    "                            click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                            chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                            chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                            time.sleep(2)\n",
    "                        while True:\n",
    "                            try:\n",
    "                                url_0=str(chrome.current_url)\n",
    "                                urlfetch()\n",
    "                                time.sleep(1)\n",
    "                                timeout = time.time() + 45\n",
    "                                try:\n",
    "                                    element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                except:\n",
    "                                    try:\n",
    "                                        chrome.refresh()\n",
    "                                        element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                    except:\n",
    "                                        continue\n",
    "                                try:\n",
    "                                    time.sleep(2)\n",
    "                                    click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                    chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                    chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                    time.sleep(2)\n",
    "                                except:\n",
    "                                    chrome.refresh()\n",
    "                                    time.sleep(2)\n",
    "                                    click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                    chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                    chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                    time.sleep(2)\n",
    "                                #time.sleep(4)\n",
    "                                url_1=str(chrome.current_url)\n",
    "                            except:\n",
    "                                urlfetch()\n",
    "                                if len(chrome.find_elements(By.XPATH,xpath_page_suivante))>0:\n",
    "                                    raise Exception(\"Failed at pressing next-page button-Timeout\")\n",
    "                                    break\n",
    "                                else:\n",
    "                                    raise Exception(\"Failed at pressing next-page button-Button not present...Check for completion\")\n",
    "                                    break\n",
    "                            if url_0==url_1:\n",
    "                                break\n",
    "                    if z['count']>1000:\n",
    "                        base2=chrome.current_url\n",
    "                        #Liste deroulantes\n",
    "                        btns = chrome.find_elements_by_css_selector('button[class=\"fc63351294 a168c6f285 d65b7d20ae a25b1d9e47\"]')\n",
    "                        for btn in btns :\n",
    "                            try :\n",
    "                                chrome.execute_script(\"arguments[0].scrollIntoView();\", btn)\n",
    "                                chrome.execute_script(\"arguments[0].click();\", btn)\n",
    "                            except:\n",
    "                                pass\n",
    "                        #If more than 1000 accomodation even after filtering by rating\n",
    "                        #we filterin based on accomodation type\n",
    "                        types= chrome.find_elements_by_css_selector('div[data-filters-item*=\"ht_id:ht_id=\"]')\n",
    "                        types = [x for x in types if len(x.text) > 0 ]\n",
    "                        typesh=[]\n",
    "                        for type_ in types:\n",
    "                            xpath_type ='//input[@name=\"{}\"]'.format(type_.get_attribute(\"data-filters-item\").split(\":\")[1])\n",
    "                            case={'label':type_.text.strip().split(\"\\n\")[0],'count':int(type_.text.strip().split(\"\\n\")[1]),'id':xpath_type}\n",
    "                            typesh.append(case)\n",
    "                        for type_ in typesh:\n",
    "                            chrome.get(base2)\n",
    "                            time.sleep(2)\n",
    "                            try :\n",
    "                                elem_type = chrome.find_element(By.XPATH,type_['id'])\n",
    "                                chrome.execute_script(\"arguments[0].scrollIntoView();\", elem_type)\n",
    "                                chrome.execute_script(\"arguments[0].click();\", elem_type)\n",
    "                                time.sleep(2)\n",
    "                                if type_['count']<=1000:\n",
    "                                    urlfetch()\n",
    "                                    time.sleep(1)\n",
    "                                    try:\n",
    "                                        element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                    except:\n",
    "                                        try:\n",
    "                                            chrome.refresh()\n",
    "                                            element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                        except:\n",
    "                                            continue\n",
    "                                    try:\n",
    "                                        time.sleep(2)\n",
    "                                        click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                        chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                        chrome.execute_script(\"arguments[0].click();\", click_element)\n",
    "                                        time.sleep(2)\n",
    "                                    except:\n",
    "                                        chrome.refresh()\n",
    "                                        time.sleep(2)\n",
    "                                        click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                        chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                        chrome.execute_script(\"arguments[0].click();\", click_element)\n",
    "                                        time.sleep(2)\n",
    "                                    while True:\n",
    "                                        try:\n",
    "                                            url_0=str(chrome.current_url)\n",
    "                                            urlfetch()\n",
    "                                            time.sleep(1)\n",
    "                                            timeout = time.time() + 45\n",
    "                                            try:\n",
    "                                                element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                            except:\n",
    "                                                try:\n",
    "                                                    chrome.refresh()\n",
    "                                                    element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                                except:\n",
    "                                                    continue\n",
    "                                            try:\n",
    "                                                time.sleep(2)\n",
    "                                                click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                                chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                                chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                                time.sleep(2)\n",
    "                                            except:\n",
    "                                                print(traceback.format_exc())\n",
    "                                                chrome.refresh()\n",
    "                                                time.sleep(2)\n",
    "                                                click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                                chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                                chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                                time.sleep(2)\n",
    "                                            url_1=str(chrome.current_url)\n",
    "                                        except:\n",
    "                                            urlfetch()\n",
    "                                            if len(chrome.find_elements(By.XPATH,xpath_page_suivante))>0:\n",
    "                                                raise Exception(\"Failed at pressing next-page button-Timeout\")\n",
    "                                                break\n",
    "                                            else:\n",
    "                                                raise Exception(\"Failed at pressing next-page button-Button not present...Check for completion\")\n",
    "                                                break\n",
    "                                        if url_0==url_1:\n",
    "                                            break\n",
    "                                if type_['count']>1000:\n",
    "                                    base3=chrome.current_url\n",
    "                                    #Liste deroulantes\n",
    "                                    btns = chrome.find_elements_by_css_selector('button[class=\"fc63351294 a168c6f285 d65b7d20ae a25b1d9e47\"]')\n",
    "                                    for btn in btns :\n",
    "                                        try :\n",
    "                                            chrome.execute_script(\"arguments[0].scrollIntoView();\", btn)\n",
    "                                            chrome.execute_script(\"arguments[0].click();\", btn)\n",
    "                                        except:\n",
    "                                            pass\n",
    "                                    #If more than 1000 accomodation even after filtering by rating and by type\n",
    "                                    #we filter based on location\n",
    "                                    locations= chrome.find_elements_by_css_selector('div[data-filters-item*=\"di:di=\"]')\n",
    "                                    locations = [x for x in locations if len(x.text) > 0 ]\n",
    "                                    time.sleep(1)\n",
    "                                    districts=[]\n",
    "                                    for loc in locations:\n",
    "                                        xpath_district ='//input[@name=\"{}\"]'.format(loc.get_attribute(\"data-filters-item\").split(\":\")[1])\n",
    "                                        case2={'label':loc.text.strip().split(\"\\n\")[0],'count':int(loc.text.strip().split(\"\\n\")[1]),'id':xpath_district}\n",
    "                                        districts.append(case2)\n",
    "                                    for district in districts:\n",
    "                                        #print(base3)\n",
    "                                        chrome.get(base3)\n",
    "                                        time.sleep(2)\n",
    "                                        try :\n",
    "                                            elem_district = chrome.find_element(By.XPATH,district['id'])\n",
    "                                            chrome.execute_script(\"arguments[0].scrollIntoView();\", elem_district)\n",
    "                                            chrome.execute_script(\"arguments[0].click();\", elem_district)\n",
    "                                            time.sleep(2)\n",
    "                                            if district['count']<=1000:\n",
    "                                                try:\n",
    "                                                    urlfetch()\n",
    "                                                    time.sleep(1)\n",
    "                                                    try:\n",
    "                                                        element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                                    except:\n",
    "                                                        try:\n",
    "                                                            chrome.refresh()\n",
    "                                                            element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                                        except:\n",
    "                                                            continue\n",
    "                                                    try:\n",
    "                                                        time.sleep(2)\n",
    "                                                        click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                                        chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                                        chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                                        time.sleep(2)\n",
    "                                                    except:\n",
    "                                                        print(traceback.format_exc())\n",
    "                                                        chrome.refresh()\n",
    "                                                        time.sleep(2)\n",
    "                                                        click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                                        chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                                        chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                                        time.sleep(2)\n",
    "                                                    while True:\n",
    "                                                        try:\n",
    "                                                            url_0=str(chrome.current_url)\n",
    "                                                            urlfetch()\n",
    "                                                            time.sleep(1)\n",
    "                                                            timeout = time.time() + 45\n",
    "                                                            try:\n",
    "                                                                element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                                            except:\n",
    "                                                                try:\n",
    "                                                                    chrome.refresh()\n",
    "                                                                    element = WebDriverWait(chrome, 20).until(EC.presence_of_element_located((By.XPATH,xpath_page_suivante)))\n",
    "                                                                except:\n",
    "                                                                    continue\n",
    "                                                            try:\n",
    "                                                                time.sleep(2)\n",
    "                                                                click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                                                chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                                                chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                                                time.sleep(2)\n",
    "                                                            except:\n",
    "                                                                chrome.refresh()\n",
    "                                                                time.sleep(2)\n",
    "                                                                click_element=chrome.find_element(By.XPATH,xpath_page_suivante)\n",
    "                                                                chrome.execute_script(\"arguments[0].scrollIntoView();\", click_element)\n",
    "                                                                chrome.execute_script(\"arguments[0].click();\",click_element)\n",
    "                                                                time.sleep(2)\n",
    "                                                            url_1=str(chrome.current_url)\n",
    "                                                        except:\n",
    "                                                            urlfetch()\n",
    "                                                            if len(chrome.find_elements(By.XPATH,xpath_page_suivante))>0:\n",
    "                                                                raise Exception(\"Failed at pressing next-page button-Timeout\")\n",
    "                                                                break\n",
    "                                                            else:\n",
    "                                                                raise Exception(\"Failed at pressing next-page button-Button not present...Check for completion\")\n",
    "                                                                break\n",
    "                                                        if url_0==url_1:\n",
    "                                                            break\n",
    "                                                except:\n",
    "                                                    options=z['label']+'//'+type_['label']+'//'+district['label']\n",
    "                                                    print('Problem with',x,'options:',options)\n",
    "                                                    continue\n",
    "                                            if district['count']>1000:\n",
    "                                                continue\n",
    "                                        except:\n",
    "                                            pass\n",
    "                            except:\n",
    "                                pass\n",
    "                except :\n",
    "                    pass\n",
    "        chrome.quit()\n",
    "        \n",
    "    except Exception as e:\n",
    "        chrome.quit()\n",
    "        with open(\"Failed_urls.txt\",\"a\") as flog:\n",
    "            print('Did not complete:',x,traceback.format_exc(),file=flog)\n",
    "\n",
    "#Set up Multithreading\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "    future_to_url = {executor.submit(searchcityurl, url): url for url in url_a_city}\n",
    "    for future in tqdm(concurrent.futures.as_completed(future_to_url),total=len(future_to_url)):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            with open(\"Failed_processes.txt\",\"a\") as flog:\n",
    "                print('%r generated an exception: %s' % (url, traceback.format_exc()),file=flog)\n",
    "        else:\n",
    "            with open(\"Completed_urls.txt\",\"a\") as flog:\n",
    "                print('%r page is completed' % url,file=flog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
